import torch
from torch.optim import Adam
from torch.utils.data import DataLoader
from torchvision.utils import make_grid

from models.VAE import CVAE
from utils import kl_divergence, one_hot_encode, reconstruction_loss


class CentralCVAE:
    def __init__(self, params):
        self.device = params["device"]
        self.epochs = params["glob_epoch"]

        self.train_data = DataLoader(params["train_data"], shuffle=True, batch_size=32)
        self.test_data = DataLoader(params["test_data"], shuffle=True, batch_size=32)

        self.num_channels = params["num_channels"]
        self.num_classes = params["num_classes"]

        self.beta = params["beta"]
        self.z_dim = params["z_dim"]
        self.num_samples_per_class = 5  # Just for display purposes

        self.model = CVAE(
            num_classes=self.num_classes,
            num_channels=self.num_channels,
            z_dim=params["z_dim"],
            image_size=params["image_size"],
            version=0,
        ).to(self.device)
        self.optimizer = Adam(self.model.parameters(), lr=params["local_LR"])

        self.writer = params["writer"]

    def train(self):
        self.model.train()

        for epoch in range(self.epochs):
            print(epoch)
            for batch_idx, (X_batch, y_batch) in enumerate(self.train_data):
                y_hot = one_hot_encode(y_batch, self.num_classes)

                X_batch, y_hot = X_batch.to(self.device), y_hot.to(self.device)

                X_recon, mu, logvar = self.model(X_batch, y_hot, self.device)

                # Calculate losses
                recon_loss = reconstruction_loss(self.num_channels, X_batch, X_recon)
                total_kld = kl_divergence(mu, logvar)
                total_loss = recon_loss + self.beta * total_kld

                # Update net params
                self.optimizer.zero_grad()
                total_loss.backward()
                self.optimizer.step()

            self.qualitative_check(
                epoch, self.model.decoder, "Novel images (good samples)", True
            )
            self.qualitative_check(
                epoch, self.model.decoder, "Novel images (poor samples)", False
            )

    def qualitative_check(self, e, dec, name, good_samples):
        """
        Display images generated by the server side decoder

        :param e: Global epoch number
        :param dec: Decoder to forward pass z + y_hot through
        :param name: Identifier for saving
        :param good_samples: Whether we should sample within the reasonable region or not
        """

        num_samples = self.num_classes * self.num_samples_per_class
        if not good_samples:
            z_sample = self.model.sample_z(
                num_samples, "uniform", uniform_width=(5, 20)
            )
        else:
            z_sample = self.model.sample_z(num_samples, "uniform")
        y = torch.tensor(
            [i for i in range(self.num_classes)] * self.num_samples_per_class
        )
        y_hot = one_hot_encode(y, self.num_classes)

        with torch.no_grad():
            z_sample, y_hot = z_sample.to(self.device), y_hot.to(self.device)
            novel_imgs = dec(z_sample, y_hot).cpu()

        self.save_images(novel_imgs, True, name, e)

    def save_images(self, images, sigmoid, name, glob_iter):
        """
        Save images so we can view their outputs

        :param images: List of images to save as a grid
        :param sigmoid: Boolean to tell us whether we are saving a novel image or one from the network
        :param name: Identifier for saving
        :param glob_iter: Global epoch number
        """

        # Use sigmoid if saving image from network
        # e.g. novel image or image from network
        if sigmoid:
            images = torch.sigmoid(images).data

        if glob_iter is not None and self.writer:
            grid = make_grid(images, nrow=self.num_classes)
            self.writer.add_image(name, grid, glob_iter)
